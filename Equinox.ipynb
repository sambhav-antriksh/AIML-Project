{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwcX4Fu8itIjNXMsbjQZNB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sambhav-antriksh/AIML-Project/blob/main/Equinox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Convolutional Neural Network on MNIST\n",
        "Equinox is one such library which provides neural network capability to JAX."
      ],
      "metadata": {
        "id": "snDPEAAkSIOO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fc687f0",
        "outputId": "c06f23bc-8315-4d4f-c49b-8c32ce0f3339"
      },
      "source": [
        "!pip install equinox"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting equinox\n",
            "  Downloading equinox-0.13.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: jax!=0.7.0,!=0.7.1,>=0.4.38 in /usr/local/lib/python3.12/dist-packages (from equinox) (0.5.3)\n",
            "Collecting jaxtyping>=0.2.20 (from equinox)\n",
            "  Downloading jaxtyping-0.3.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from equinox) (4.15.0)\n",
            "Collecting wadler-lindig>=0.1.0 (from equinox)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jaxlib<=0.5.3,>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (0.5.3)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox) (1.16.2)\n",
            "Downloading equinox-0.13.1-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, jaxtyping, equinox\n",
            "Successfully installed equinox-0.13.1 jaxtyping-0.3.3 wadler-lindig-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63747e29"
      },
      "source": [
        "After running the above cell to install `equinox`, you should be able to run the original cell without the `ModuleNotFoundError`. The error occurred because Python couldn't find the `equinox` library when trying to import it. Installing the library makes it available for use."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import equinox as eqx\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import torch\n",
        "import torchvision\n",
        "from jaxtyping import Array,Float,Int,PyTree\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lqTrRRqpS-mC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE=64\n",
        "LEARNING_RATE=3E-4\n",
        "STEPS=300\n",
        "PRINT_EVERY=30\n",
        "SEED=5678\n",
        "key=jax.random.PRNGKey(SEED)"
      ],
      "metadata": {
        "id": "mOk6e2B6TdTj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The DATSET"
      ],
      "metadata": {
        "id": "Euke3SKvUDDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalise_data=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.5,),(0.5,))])\n",
        "train_dataset=torchvision.datasets.MNIST(root='./data',train=True,download=True,transform=normalise_data)\n",
        "test_dataset=torchvision.datasets.MNIST(root='./data',train=False,download=True,transform=normalise_data)\n",
        "trainloader= torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)  #iterator (images,label)\n",
        "testloader= torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2_dOfm3T8Ds",
        "outputId": "ebdfa5ea-69da-402b-a81e-bccd556bc834"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 35.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.41MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.4MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking our data\n",
        "# trainloader gives me the batches of the data\n",
        "dummy_x,dummy_y=next(iter(trainloader))\n",
        "dummy_x=dummy_x.numpy()  #converts pytorch tensor to numpy array #np would not work because no such method\n",
        "dummy_y=dummy_y.numpy()\n",
        "print(dummy_x.shape)\n",
        "print(dummy_y.shape)\n",
        "print(dummy_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHZxC9AHU5U9",
        "outputId": "45522228-f93b-489b-c743-66ac892f2337"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 1, 28, 28)\n",
            "(64,)\n",
            "[7 6 0 9 4 3 8 8 2 6 3 3 9 8 7 0 1 7 2 9 9 9 8 5 4 9 8 9 8 8 5 3 9 4 9 5 7\n",
            " 9 3 9 8 5 1 9 8 4 9 8 0 4 2 1 6 8 8 1 8 1 0 8 2 8 8 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images,labels in trainloader:\n",
        "  print(images.shape)\n",
        "  print(labels.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-3hqDtjW7Xs",
        "outputId": "31f0f3f0-3e7d-4a85-a349-64a4890d5e6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Model"
      ],
      "metadata": {
        "id": "8dLyrfbIqKau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(eqx.Module):\n",
        "    layers: list\n",
        "\n",
        "    def __init__(self, key):\n",
        "        key1, key2, key3, key4 = jax.random.split(key, 4)\n",
        "        # Standard CNN setup: convolutional layer, followed by flattening,\n",
        "        # with a small MLP on top.\n",
        "        self.layers = [\n",
        "            eqx.nn.Conv2d(1, 3, kernel_size=4, key=key1),\n",
        "            eqx.nn.MaxPool2d(kernel_size=2),\n",
        "            jax.nn.relu,\n",
        "            jnp.ravel,\n",
        "            eqx.nn.Linear(1728, 512, key=key2),\n",
        "            jax.nn.sigmoid,\n",
        "            eqx.nn.Linear(512, 64, key=key3),\n",
        "            jax.nn.relu,\n",
        "            eqx.nn.Linear(64, 10, key=key4),\n",
        "            jax.nn.log_softmax,\n",
        "        ]\n",
        "\n",
        "    def __call__(self, x: Float[Array, \"1 28 28\"]) -> Float[Array, \"10\"]:\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "key, subkey = jax.random.split(key, 2)\n",
        "model = CNN(subkey)"
      ],
      "metadata": {
        "id": "L_zeTvIkqKG4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(model: CNN,x:Float[Array,\"batch 1 28 28\"],y: Int[Array,'batch']) -> Float[Array, \"\"]:\n",
        "  pred_y=jax.vmap(model)(x)            # Arguments passed are vectorized in the leading axis now it passes over batch\n",
        "  return cross_entropy(y,pred_y)\n",
        "\n",
        "def cross_entropy(y: Int[Array,'batch'],pred_y:Float[Array,'batch 10'])-> Float[Array,\"\"]:\n",
        "  pred_y= jnp.take_along_axis(pred_y,jnp.expand_dims(y,1),axis=1)\n",
        "  return -jnp.mean(pred_y)\n",
        "\n",
        "# Example loss\n",
        "loss_value=loss(model,dummy_x,dummy_y)\n",
        "print(loss_value)\n",
        "# Example inference\n",
        "output=jax.vmap(model)(dummy_x)\n",
        "print(output.shape)  #batch of predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBK8rbDqRRzl",
        "outputId": "1b425873-1a70-40e0-a61b-8600629f0f1c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3046346\n",
            "(64, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "13NhRhXMhoOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss= eqx.filter_jit(loss)\n",
        "@eqx.filter_jit\n",
        "\n",
        "def compute_accuracy(model: CNN, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \"batch\"]) -> Float[Array, \"\"]:\n",
        "  '''Compute the average accuracy on a batch '''\n",
        "  pred_y=jax.vmap(model)(x)\n",
        "  pred_y=jnp.argmax(pred_y,axis=1)\n",
        "  return jnp.mean(y==pred_y)"
      ],
      "metadata": {
        "id": "wsF1q72fdtA7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model: CNN, testloader: torch.utils.data.DataLoader):\n",
        "  avg_loss= 0\n",
        "  avg_acc= 0\n",
        "  for x,y in testloader:\n",
        "    x=x.numpy()\n",
        "    y=y.numpy()\n",
        "    avg_loss+=loss(model,x,y)\n",
        "    avg_acc+=compute_accuracy(model,x,y)\n",
        "    #print(y)\n",
        "  return avg_loss/len(testloader),avg_acc/len(testloader)"
      ],
      "metadata": {
        "id": "vb5graFQjQ8M"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model,testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdii0Kzyj2bb",
        "outputId": "48b46293-2569-4766-8196-3579dd949ef4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array(2.311523, dtype=float32), Array(0.10360271, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train our Model"
      ],
      "metadata": {
        "id": "jddRXfJNwPnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim= optax.adamw(LEARNING_RATE)"
      ],
      "metadata": {
        "id": "af4rxjvuwSCQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: CNN, trainloader: torch.utils.data.DataLoader,testloader: torch.utils.data.DataLoader,optim: optax.GradientTransformation, steps: int, print_every: int,)->CNN:\n",
        "  opt_state=optim.init(eqx.filter(model,eqx.is_array))\n",
        "  @eqx.filter_jit\n",
        "  def make_step(model: CNN, opt_state: PyTree, x: Float[Array,\"batch 1 28 28\"],y: Int[Array,\"batch\"],):\n",
        "    loss_value,grads= eqx.filter_value_and_grad(loss)(model,x,y)\n",
        "    updates,opt_state=optim.update(grads,opt_state,eqx.filter(model,eqx.is_array))\n",
        "    model=eqx.apply_updates(model,updates)\n",
        "    return model,opt_state,loss_value\n",
        "\n",
        "  def infinite_trainloader():\n",
        "    while True:\n",
        "      yield from trainloader\n",
        "\n",
        "  for step,(x,y) in zip(range(steps),infinite_trainloader()):\n",
        "    x=x.numpy()\n",
        "    y=y.numpy()\n",
        "    model,opt_state,train_loss= make_step(model,opt_state,x,y)\n",
        "    if (step%print_every)==0 or ( step == steps-1):\n",
        "      test_loss,test_accuracy= evaluate(model,testloader)\n",
        "      print(f'{step=},train_loss={train_loss.item()},'f'test_loss={test_loss.item()},test_accuracy={test_accuracy.item()}')\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "lyawzNmCxrYy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=train(model,trainloader,testloader,optim,STEPS,PRINT_EVERY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Ju4VK24nzg",
        "outputId": "921b8df3-4a21-464c-9531-a6630ebe4b6f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step=0,train_loss=2.2766408920288086,test_loss=2.2788712978363037,test_accuracy=0.24452626705169678\n",
            "step=30,train_loss=1.9921276569366455,test_loss=1.9998061656951904,test_accuracy=0.4595939517021179\n",
            "step=60,train_loss=1.670916199684143,test_loss=1.597533941268921,test_accuracy=0.6569466590881348\n",
            "step=90,train_loss=1.2031606435775757,test_loss=1.2037876844406128,test_accuracy=0.6993431448936462\n",
            "step=120,train_loss=0.8097004890441895,test_loss=0.901013970375061,test_accuracy=0.7844347357749939\n",
            "step=150,train_loss=0.8470339775085449,test_loss=0.687089741230011,test_accuracy=0.8458399772644043\n",
            "step=180,train_loss=0.5941312909126282,test_loss=0.5600081086158752,test_accuracy=0.8653463125228882\n",
            "step=210,train_loss=0.39332640171051025,test_loss=0.47468823194503784,test_accuracy=0.8818670511245728\n",
            "step=240,train_loss=0.330039381980896,test_loss=0.41024479269981384,test_accuracy=0.8958996534347534\n",
            "step=270,train_loss=0.3951440453529358,test_loss=0.3695693016052246,test_accuracy=0.9050557613372803\n",
            "step=299,train_loss=0.2716626524925232,test_loss=0.3396523594856262,test_accuracy=0.9084395170211792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sAzNBhlL6YZc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}